{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pritam\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Preparation (Time slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "\n",
    "def date_prep():\n",
    "    N=365*20\n",
    "    end=datetime.now()\n",
    "    start=datetime.now()-timedelta(days=N)\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing csvs of stok Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "def prepare_csv(comp_name):\n",
    "    start, end = date_prep()\n",
    "    try:\n",
    "        df = web.DataReader(comp_name, 'yahoo', start, end)\n",
    "        df.to_csv('{}.csv'.format(comp_name), index=False)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the predicting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.models import Sequential\\nfrom keras.layers import LSTM, Dense, Dropout\\n\\ndef create_model(x_train):\\n    ####MODEL cretion #####\\n    model = Sequential()  # define the Keras model\\n    model.add(\\n        LSTM(units=240, return_sequences=True, input_shape=(x_train.shape[1], 6)))  # 120 neurons in the hidden layer\\n    ##return_sequences=True makes LSTM layer to return the full history including outputs at all times\\n    model.add(Dropout(0.2))\\n    model.add(LSTM(units=520, return_sequences=True))\\n    model.add(Dropout(0.2))\\n    model.add(LSTM(units=520, return_sequences=True))\\n    model.add(Dropout(0.2))\\n    model.add(LSTM(units=128, return_sequences=False))\\n    model.add(Dropout(0.2))\\n    model.add(Dense(units=1, activation='sigmoid'))\\n    # adding optimizer and loss function\\n    model.compile(optimizer='adam', loss='mean_squared_error')\\n    return model\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def create_model(x_train):\n",
    "    ####MODEL cretion #####\n",
    "    model = Sequential()  # define the Keras model\n",
    "    model.add(\n",
    "        LSTM(units=240, return_sequences=True, input_shape=(x_train.shape[1], 6)))  # 120 neurons in the hidden layer\n",
    "    ##return_sequences=True makes LSTM layer to return the full history including outputs at all times\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=520, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=520, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=128, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    # adding optimizer and loss function\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef train_model(comp_name):\\n    # reading a csv file\\n    prepare_csv(comp_name)\\n    df = pd.read_csv('{}.csv'.format(comp_name))\\n\\n    df.dropna(how='any', inplace=True)\\n\\n    training = df\\n\\n    sc = MinMaxScaler()\\n    sc.fit(training)\\n    training_set_scaled = sc.fit_transform(training)\\n\\n    X_train = []\\n    y1_train = []\\n    timestamp = 60\\n    length = len(training)\\n    \\n    #####Open   2, High  0, Low   1, Close   3, Adj Close 5####\\n    ################ adj close\\n    for i in range(timestamp, length + 1):\\n        X_train.append(training_set_scaled[i - timestamp:i, ])\\n\\n    for i in range(timestamp, length + 1):\\n        y1_train.extend(training_set_scaled[i:i + 1, 5]) #adj close->5\\n    x_train = []\\n    y1_train = np.array(y1_train)\\n    x_train = X_train[:y1_train.shape[0]]\\n    y1_train = np.reshape(y1_train, (-1, 1))\\n    x_train = np.array(x_train)\\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\\n    model1 = create_model(x_train)\\n    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\\n    # storing the model\\n    model1.save('StockPredictor{}AdjClose.model'.format(comp_name))\\n    x_train = []\\n    y1_train = []\\n\\n    #################close\\n    for i in range(timestamp, length + 1):\\n        X_train.append(training_set_scaled[i - timestamp:i, ])\\n\\n    for i in range(timestamp, length + 1):\\n        y1_train.extend(training_set_scaled[i:i + 1, 3]) #close->3\\n    x_train = []\\n    y1_train = np.array(y1_train)\\n    x_train = X_train[:y1_train.shape[0]]\\n    y1_train = np.reshape(y1_train, (-1, 1))\\n    x_train = np.array(x_train)\\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\\n    model1 = create_model(x_train)\\n    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\\n    # storing the model\\n    model1.save('StockPredictor{}Close.model'.format(comp_name))\\n    x_train = []\\n    y1_train = []\\n\\n    ############################LOW\\n    for i in range(timestamp, length + 1):\\n        X_train.append(training_set_scaled[i - timestamp:i, ])\\n\\n    for i in range(timestamp, length + 1):\\n        y1_train.extend(training_set_scaled[i:i + 1, 1]) #low->1\\n    x_train = []\\n    y1_train = np.array(y1_train)\\n    x_train = X_train[:y1_train.shape[0]]\\n    y1_train = np.reshape(y1_train, (-1, 1))\\n    x_train = np.array(x_train)\\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\\n    model1 = create_model(x_train)\\n    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\\n    # storing the model\\n    model1.save('StockPredictor{}Low.model'.format(comp_name))\\n    x_train = []\\n    y1_train = []\\n    ##############High\\n    for i in range(timestamp, length + 1):\\n        X_train.append(training_set_scaled[i - timestamp:i, ])\\n\\n    for i in range(timestamp, length + 1):\\n        y1_train.extend(training_set_scaled[i:i + 1, 0]) #high->0\\n    x_train = []\\n    y1_train = np.array(y1_train)\\n    x_train = X_train[:y1_train.shape[0]]\\n    y1_train = np.reshape(y1_train, (-1, 1))\\n    x_train = np.array(x_train)\\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\\n    model1 = create_model(x_train)\\n    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\\n    # storing the model\\n    model1.save('StockPredictor{}High.model'.format(comp_name))\\n    x_train = []\\n    y1_train = []\\n    ################## Open\\n    for i in range(timestamp, length + 1):\\n        X_train.append(training_set_scaled[i - timestamp:i, ])\\n\\n    for i in range(timestamp, length + 1):\\n        y1_train.extend(training_set_scaled[i:i + 1, 2]) #open->2\\n    x_train = []\\n    y1_train = np.array(y1_train)\\n    x_train = X_train[:y1_train.shape[0]]\\n    y1_train = np.reshape(y1_train, (-1, 1))\\n    x_train = np.array(x_train)\\n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\\n    model1 = create_model(x_train)\\n    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\\n    # storing the model\\n    model1.save('StockPredictor{}Open.model'.format(comp_name))\\n    x_train = []\\n    y1_train = []\\n\\n    os.remove(comp_name + '.csv')\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def train_model(comp_name):\n",
    "    # reading a csv file\n",
    "    prepare_csv(comp_name)\n",
    "    df = pd.read_csv('{}.csv'.format(comp_name))\n",
    "\n",
    "    df.dropna(how='any', inplace=True)\n",
    "\n",
    "    training = df\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    sc.fit(training)\n",
    "    training_set_scaled = sc.transform(training)\n",
    "    filename=f'{comp_name}Scale.pkl'\n",
    "    joblib.dump(sc,filename)\n",
    "    \n",
    "    X_train = []\n",
    "    y1_train = []\n",
    "    timestamp = 60\n",
    "    length = len(training)\n",
    "    \n",
    "    #####Open   2, High  0, Low   1, Close   3, Adj Close 5####\n",
    "    ################ adj close\n",
    "    for i in range(timestamp, length + 1):\n",
    "        X_train.append(training_set_scaled[i - timestamp:i, ])\n",
    "\n",
    "    for i in range(timestamp, length + 1):\n",
    "        y1_train.extend(training_set_scaled[i:i + 1, 5]) #adj close->5\n",
    "    x_train = []\n",
    "    y1_train = np.array(y1_train)\n",
    "    x_train = X_train[:y1_train.shape[0]]\n",
    "    y1_train = np.reshape(y1_train, (-1, 1))\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\n",
    "    model1 = create_model(x_train)\n",
    "    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\n",
    "    # storing the model\n",
    "    model1.save('StockPredictor{}AdjClose.model'.format(comp_name))\n",
    "    x_train = []\n",
    "    y1_train = []\n",
    "\n",
    "    #################close\n",
    "    for i in range(timestamp, length + 1):\n",
    "        X_train.append(training_set_scaled[i - timestamp:i, ])\n",
    "\n",
    "    for i in range(timestamp, length + 1):\n",
    "        y1_train.extend(training_set_scaled[i:i + 1, 3]) #close->3\n",
    "    x_train = []\n",
    "    y1_train = np.array(y1_train)\n",
    "    x_train = X_train[:y1_train.shape[0]]\n",
    "    y1_train = np.reshape(y1_train, (-1, 1))\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\n",
    "    model1 = create_model(x_train)\n",
    "    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\n",
    "    # storing the model\n",
    "    model1.save('StockPredictor{}Close.model'.format(comp_name))\n",
    "    x_train = []\n",
    "    y1_train = []\n",
    "\n",
    "    ############################LOW\n",
    "    for i in range(timestamp, length + 1):\n",
    "        X_train.append(training_set_scaled[i - timestamp:i, ])\n",
    "\n",
    "    for i in range(timestamp, length + 1):\n",
    "        y1_train.extend(training_set_scaled[i:i + 1, 1]) #low->1\n",
    "    x_train = []\n",
    "    y1_train = np.array(y1_train)\n",
    "    x_train = X_train[:y1_train.shape[0]]\n",
    "    y1_train = np.reshape(y1_train, (-1, 1))\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\n",
    "    model1 = create_model(x_train)\n",
    "    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\n",
    "    # storing the model\n",
    "    model1.save('StockPredictor{}Low.model'.format(comp_name))\n",
    "    x_train = []\n",
    "    y1_train = []\n",
    "    ##############High\n",
    "    for i in range(timestamp, length + 1):\n",
    "        X_train.append(training_set_scaled[i - timestamp:i, ])\n",
    "\n",
    "    for i in range(timestamp, length + 1):\n",
    "        y1_train.extend(training_set_scaled[i:i + 1, 0]) #high->0\n",
    "    x_train = []\n",
    "    y1_train = np.array(y1_train)\n",
    "    x_train = X_train[:y1_train.shape[0]]\n",
    "    y1_train = np.reshape(y1_train, (-1, 1))\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\n",
    "    model1 = create_model(x_train)\n",
    "    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\n",
    "    # storing the model\n",
    "    model1.save('StockPredictor{}High.model'.format(comp_name))\n",
    "    x_train = []\n",
    "    y1_train = []\n",
    "    ################## Open\n",
    "    for i in range(timestamp, length + 1):\n",
    "        X_train.append(training_set_scaled[i - timestamp:i, ])\n",
    "\n",
    "    for i in range(timestamp, length + 1):\n",
    "        y1_train.extend(training_set_scaled[i:i + 1, 2]) #open->2\n",
    "    x_train = []\n",
    "    y1_train = np.array(y1_train)\n",
    "    x_train = X_train[:y1_train.shape[0]]\n",
    "    y1_train = np.reshape(y1_train, (-1, 1))\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 6))\n",
    "    model1 = create_model(x_train)\n",
    "    model1.fit(x_train, y1_train, epochs=5, batch_size=32)  # ,callbacks=[tensorboard])\n",
    "    # storing the model\n",
    "    model1.save('StockPredictor{}Open.model'.format(comp_name))\n",
    "    x_train = []\n",
    "    y1_train = []\n",
    "\n",
    "    os.remove(comp_name + '.csv')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Actually the high block is accessed in the actual ##TODO rethinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_model('SBIN.NS')\\ntrain_model('TCS.NS')\\ntrain_model('WIPRO.NS')\\ntrain_model('UNITEDBNK.BO')\\ntrain_model('RELIANCE.NS')\\ntrain_model('^BSESN')\\ntrain_model('^NSEI')\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_model('SBIN.NS')\n",
    "train_model('TCS.NS')\n",
    "train_model('WIPRO.NS')\n",
    "train_model('UNITEDBNK.BO')\n",
    "train_model('RELIANCE.NS')\n",
    "train_model('^BSESN')\n",
    "train_model('^NSEI')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
